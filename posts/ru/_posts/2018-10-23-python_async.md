---
layout: post
lang: ru
ref: python_async
title: "Несинхронный Python"
comments: true
tags: [Python asyncio threads fork]
redirect_from: "/posts/ru/python_async/"
---

<style type="text/css">
  h2 {
    content: "";
    clear: both;
  }
</style>

В арсенале современного программиста есть множество средств для создания не синхронного кода
(выполняемого не последовательно).

Серебряной пули среди этих инструментов нет, надо выбирать под конкретную задачу.

В этой статье я сделаю краткий обзор, который позволит вам осознанно делать этот выбор.

Термин "не синхронный" я использую потому, что хотел бы поговорить о всем многообразии методик,
а не только, например, о многопоточности.

## Типы задач, требующие несинхронного кода

### Много ввода-вывода

В современных компьютерах существенно отличается скорость процессора и скорость подсистем ввода-вывода.
К подсистемам ввода-вывода в первую очередь относятся файлы на диске и сетевые соединения.

Допустим, вы пишете веб-сервер, обрабатывающий запросы.

Клиент устанавливает TCP-соединение с вашим сервером, после чего начинает отправлять вам в рамках этого
соединения уже HTTP-запрос, чтобы получить веб-страницу.
Даже крошечный HTTP-запрос требует времени для отправки - большего, чем начальное установление TCP
соединения.
Потом еще надо будет отправить клиенту сформированную вам веб-страницу.
Если в этот момент к вам придут другие клиенты, они только установят на уровне операционной системы TCP
соединения, и будут стоять в очереди, ждать, когда осободится ваш обработчик.
Который, в свою очередь, просто ждет завершения ввода-вывода операционной системой.

Очевидно, что так никто не работает.

Операционная система умеет эффективно выполнять много процессов ввода-вывода параллельно, нам надо
только суметь загрузить ее этой работой. И заниматься другими задачами, пока она их выполняет.

Кроме того, возможность не ожидать, пока особо массивная страница отдается какому-то клиенту (и который
пнимает, что запросил много и готов ждать), позволяет не затормаживать обслуживание тех клиентов, кто
запросил небольшие страницы, и поэтому совсем не ожидает, что ответ получит очень нескоро, только
когда мы отдадим большую страницу другому клиенту, о котором он не знает и не хочет ничего знать.
 
### Много вычислений

Нам надо посчитать что-то вычислительно сложное. Считать это последователно долго.
Хочется использовать полную мощность современного компьютера, в котором, как правило не один процессор.

### Фоновая работа

Допустим, у нас веб-сервер, показывающий прогноз погоды.
Но раз в 10 минут нам надо получить данные от поставщика данных. А потом, может и обработать.
Т.е. нам надо регулярно делать что-то, что занимает много времени, либо потому что там большой ввод-вывод,
либо потому что надо что-то долго считать.
Нам не так уж важно сделать это быстро, но совершенно немыслимо прерывать на это время работу сайта - он
должен продолжать оперативно обслуживать клиентов. 

## Методики решения

![](/images/process_seq.png){:style="margin-right: 7px; margin-top: 7px;"}
![](/images/process_par_multy.png){:style="float: right; clear: both; margin-right: 7px;margin-top: 7px;"}
![](/images/process_par.png){:style="float: right; margin-right: 7px;margin-top: 7px;"}

На первой картинке у нас показана ситуация до того, как мы выбрали способ выполнять код не синхронно.
Мы выполняем его последовательно.
В результате, если нам понадобилось выполнить новую задачу, когда мы заняты предыдущей,
новая задача ждет в очереди.

На второй картинке мы псевдо-параллельно выполняем обе функции, делая поочередно небольшой 
кусочек каждой из них. 
Поскольку вторая функция требует меньше времени, мы ответим на нее быстрее, чем на первую.
В итоге мы быстрее ответим на вторую функцию, хотя и не сможем обработать больше функций.

Как именно распилить функции на кусочки - предмет для следующего раздела (про способы).

Вторая картинка также иллюстрирует ситуацию, когда мы в периоды ожидания первой функции,
когда ей все равно не нужны ресурсы для выполнения, выполняем вторую функцию.
Это позволяет более эффективно использовать ресурсы и выполнить больше функций за единицу
времени.

На практике, способ разрезания функций на кусочки также позволяет в периоды простоя не тратить
на простаивающие функции ресурсы, в итоге получаем оба преимущества - и быстрее отвечаем на более
короткие функци, и более эффективно используем ресурсы.  
 
На третьей картинке мы задействовали все процессоры и выполняем процессы параллельно на всех.

## Способы решения

Все описаные ниже способы решают проблему как параллельного выполнения (быстрый ответ на короткие функции), так и эффективное
так и использование периодов простоя (не тратится время на ожидающие ввода-вывода функции, хотя в некоторых 
способах решения об этом надо явно заботится и не гарантируется 100% эффективность).

## Python GIL

Конкретно для Python реализация не синхронного выполнения усложняется имеющимся в нем Global 
Interpreter Lock (GIL).
Который, не позволяет интерпретатору работать параллельно в разных нитях (threads).
GIL может сниматься C-кодом, а также при выполнении ввода-вывода.
Поэтому выполнять вычисления NumPy или ждать завершения ввода-вывода, не смотря на GIL быстрее в 
нескольких нитях, чем в одной (поскольку заметную часть времени GIL будет снят).
Но несколько нитей не дадут никакого выигрыша, если выполнять в них только Python-код.
Точнее, будет даже медленнее, из-за накладных расходов на старт нитей.


## Много процессов операционной системы

Самый простой и древний способ.

Без специального инструментария это запуск нашей программы нужное число раз.
Нет никакого пересечения по памяти или общим переменным, все идельально изолировано.
Но если нам надо запускать тысячи таких процессов, то это будет крайне неэффективная
работа операционной системы. Не говоря уже о том, что у вас вряд ли хватит оперативной памяти
на запуск такого количества интерпретаторов Python.

В Python есть очень удобный модуль [multiprocessing](https://docs.python.org/3/library/multiprocessing.html)
Позволяющий в несколько строк, независимо от операционной системы, запустить функции в параллельных процессах.

{% highlight python %}
{% include src/multiprocessing.py %}
{% endhighlight %}
    hello alice
    hello bob
    alice done!
    bob done!

##### Свойства
Делегируем задачу распараллельвания выполнения операционной системе.

В древние времена, когда еще не было вытесняющей многозадачности,
операционная система обеспечивала параллельность выполнения процессов за счет прерываний
и кооперативной многозадачности.
Процессы выполнялись до тех пор, пока работа процессора не прерывалась аппаратным прерыванием,
либо процесс не запрашивал что-то у операционной системы. И после этого операционная система могла
дать подышать другому процессу.

Сейчас операционные системы используют вытесняющую многозадачность - процессы получают для работы 
небольшие интервалы времени, а далее контекст переключается на следующий в очереди планировщика
процесс. Контекст переключается очень эффективно, без заметных затрат времени.
И, конечно, если в системе есть несколько процессоров, то процессы одновременно выполняются на каждом. 

##### Плюсы
* Распараллеливанием ресурсов занимается операционная система, умеющая это делать эффективно.
* Абсолютная изоляция. Нет никакого риска испортить состояние объектов, потому, что общих 
объектов, и даже общего интерпретатора вообще нет.
* Нет Python GIL.

##### Минусы
* Высокие накладные расходы на запуск параллельного процесса
* Параллельные процессы потребляют массу оперативной памяти и ресурсов операционной системы
* Переключение процессов современные операционные системы выполняют очень эффективно, но это все же
один из самых дорогих способов переключения.
* Не простое и не дешевое межпроцессое взаимодействие.
Модуль multiprocessing предоставляет нам набор очень удобных инструментов для того чтобы скрыть сложность
этого взаимодействия. Но это не снижает его реальную стоимость.

##### Области применения
Небольшое число процессов:
* По одному на процессор, если речь о вычислительно тяжелых функциях
* Разумное количество (для эффективного управления операционной системой), чтобы создать
очередь ожидания ввода-вывода или каких-то событий, по которым надо выполнить функции в этих
процессах
* Логически и по реализации существенно изолированные задачи, которые надо выполнять параллельно
с основным процессом. И которые не хочется переписывать и отлаживать для стабильной работы
в многопоточной или асинхронной среде.
    
## Параллельное выполнение в нитях (threads)
##### Свойства
Строго говоря, как и в предыдущем случае, мы делегируем задачу операционной системе.
Именно она планирует выполнение нитей.

##### Плюсы
* Если обеспечивается принцип "каждая нить на своем процессоре", то получаем максимально приближенное
к железу решение, позволяющее максмально эффективно исопльзовать ресурсы. Впрочем, это как с языком 
ассемблера - теоретическая возможность не означает практичность (см. минусы).
* Один из самых старых способов, поэтому для него наработано море методик и документации.

##### Минусы
* Запуск нитей существенно выше, чем процессов, но не супер-дешевый
* Переключение достаточно эффективно но не существенно дешевле, чем в способе переключения процессов.
* Нельзя запускать нити тысячами - в таком случае операционная система будет тратить больше времени на
переключением между ними, чем на полезную работу.
* Способ знаменит неисчислимым количяеством способов отстрелить себе ногу. Нужна очень высокая 
квалификация для написания стабильного и эффективного решение. Отладка крайне сложна. Поиск дефектов
требует сложного тестирования.
* Python GIL приводит к тому, что выполнение собственно Python кода не происходит параллельно в разных нитях.

##### Области применения
Фоновая работа или эффективное использование ожидания ввода вывода.
Для отсносительно небольшого числа функций.
Без необходимости раскрашивать код этих функций, как описано для последующих решение.
И желательно чтобы функции требовали минимального межвзаимодействия, иначе реализация и отладка будет
очень непростой.

##  Зеленые потоки и asynio corutines

Кооперативная многозадачность.

Имеется цикл выполнения всех зеленых потоков и corutines.
Он последовательно берет очередной из работающих зеленых потоков/corutine и отдает ему управление.
Если поток/corutine в ожидании ввода-вывода или какого-то события, то мы его пропускаем и не тратим пока
на него время.

Вся магия в двух моментах.
Во-1х потоки/corutine должны уметь сами отдавать управление назад циклу выполнения, чтобы дать подышать
другим потокам/corutine. Отсюда и название "кооперативная многозадачность" - все это работает до тех пор,
пока все соблюдают правила. Если кто-то захватит управление и не будет его отдавать, то получим
традиционное синхронное выполнение.
Во-2х потоки/corutine должны явно сообщать циклу выполнения, что они чего-то ожидают. 

Различие между этими двумя техниками только в способе дробления потоков/corutine на кусочки.

###  Зеленые потоки

В основе лежит monkey patching, который преобразут основные библиотеки для ввода вывода так, что
при обращении к ним реально управление передается циклу управления.
В итоге при всех ожиданиях зеленый поток добровольно, хотя и незаметно для себя, дает возможность
циклу управления выполнить другие зеленые потоки.

##### Свойства
Можно попробовать применить для кода, которые не предполагал асинхронность.
Хотя результат и не гарантирован, причем проблемы не просто будет сразу обнаружить.

##### Плюсы
* Не надо существенно раскрашивать, как в asynio, код зеленого потока.
* Дешевое переключение между потоками
* Потоков может быть много
* Накладные расходы невысоки 

##### Минусы
* Monkey patching неочевиден, поэтому даже при большом опыте вы будет очень приближенно понимать, что 
происходит в приложении. И оптимизация работы станет увлекательным научным приключением.

### Asynio
##### Свойства
Можно внедрять постепенно (не обязательно сразу весь код украшать async/await), но, очевидно,
не рационально использовать с большим объемом унаследованого кода.
Или если у используемых вами библиотек ввода-вывода нет asynio вариантов.

##### Плюсы
* В полном соответствии с Python принципами "явное лучше неявного" - полная прозрачность происходящего
* Дешевое переключение между потоками
* Потоков может быть много
* Накладные расходы невысоки
* В сочетании с отсутствие monkey patching получаем достаточно простое логически решение.
Которое на порядок проще писать и отлаживать, чем multy threading. 

##### Минусы
* Надо очень существенно изменять исходные код.
После чего его использование в синхронном режиме, хотя и вполне возможно, но уже довольгно громоздко
и менее эффективно (придется все равно стартовать цикл обработки).

## Call-back hell

Для полноты упомяну js-way.
Мы можем при вызове ввода-вывода указывать функции, которые после ввода-вывода надо будет вызвать.
И после этого продолжать выполнение нашей программы.

Очевидно, что при этом приложение становится конечным автоматом.
Вы пишете не столько код выполнения программы, сколько море обработчиков всевозможных событий.
Которые, зачастую, логически совсем не выглядят событием (скажем, завершение открытия файла).

В принципе, несложный интерфейс пользователя так можно релаизовать.
Но как только нам надо сделать мало-мальски сложную обработку, мы получим очень запутанное приложение.

## Циклы выполнения на libuv и прочие

В описанном выше я не упоминал, как именно цикл выполнения понимает, что операционная система,
например, закончила считывание файла, и, значит, управление можно опять давать той coroutine что
этого ожидала.

Конкретные реализации не только существенно зависят от операционных систем.
Но и в рамках каждой операционной системы может быть несколько способов этого сделать.

В результате имеем несколько вариантов реализации цикла выполнения.
Понять, какой из них лучше, и для чего - нетривиальное исследование.
Сложность связана с тем, что эффективность хочется померить в реальных условиях.
Но реальный ввод-вывод очень сложно сделать повторяемым.
